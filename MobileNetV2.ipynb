{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPg4+qO3oAbeQIK+zaz5NfP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TetianaKobuta/FractureXrayClassifier/blob/main/MobileNetV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehf27kCbn_0_"
      },
      "outputs": [],
      "source": [
        "#–≤–∏—Ç—è–≥—É—î–º–æ –∑ kaggle –¥–∞—Ç—Å–µ—Ç\n",
        "import json\n",
        "import os\n",
        "\n",
        "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è ~/.kaggle —ñ –∑–∞–ø–∏—Å —Ç–æ–∫–µ–Ω–∞\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
        "    json.dump({\"username\":\"tetianakobuta\",\"key\":\"f0c1fdfbdfd80e8facd601c38501e8ae\"}, f)\n",
        "\n",
        "# –î–æ—Å—Ç—É–ø–∏\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 600)\n",
        "\n",
        "# –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è Kaggle CLI\n",
        "!pip install -q kaggle\n",
        "\n",
        "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É\n",
        "!kaggle datasets download -d bmadushanirodrigo/fracture-multi-region-x-ray-data\n",
        "\n",
        "# –†–æ–∑–ø–∞–∫–æ–≤–∫–∞\n",
        "!unzip -q fracture-multi-region-x-ray-data.zip -d fracture_dataset\n",
        "\n",
        "# –ü–µ—Ä–µ–≤—ñ—Ä–∏–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É\n",
        "for root, dirs, files in os.walk('fracture_dataset'):\n",
        "    print(\"üìÅ\", root)\n",
        "    print(\"üìÇ\", dirs)\n",
        "    print(\"üñºÔ∏è\", files[:3])\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "P24nN2htoIJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models\n",
        "from PIL import ImageFile\n",
        "import math\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# === –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è ===\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "# === –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∏ ===\n",
        "train_gen = ImageDataGenerator(rescale=1./255)\n",
        "val_gen = ImageDataGenerator(rescale=1./255)\n",
        "test_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_path = 'fracture_dataset/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train'\n",
        "val_path = 'fracture_dataset/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/val'\n",
        "test_path = 'fracture_dataset/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test'\n",
        "\n",
        "train_data = train_gen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_data = val_gen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_data = test_gen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# === –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω—å ===\n",
        "train_samples = train_data.samples\n",
        "val_samples = val_data.samples\n",
        "test_samples = test_data.samples\n",
        "\n",
        "steps_per_epoch = math.ceil(train_samples / BATCH_SIZE)\n",
        "validation_steps = math.ceil(val_samples / BATCH_SIZE)\n",
        "\n",
        "print(f\"\\nüîç –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
        "print(f\"  üìÅ Train: {train_samples} –∑–æ–±—Ä–∞–∂–µ–Ω—å ‚Üí {steps_per_epoch} –∫—Ä–æ–∫—ñ–≤/–µ–ø–æ—Ö—É\")\n",
        "print(f\"  üìÅ Val: {val_samples} –∑–æ–±—Ä–∞–∂–µ–Ω—å ‚Üí {validation_steps} –∫—Ä–æ–∫—ñ–≤/–µ–ø–æ—Ö—É\")\n",
        "print(f\"  üìÅ Test: {test_samples} –∑–æ–±—Ä–∞–∂–µ–Ω—å\")\n",
        "\n",
        "# === –ü–æ–±—É–¥–æ–≤–∞ –º–æ–¥–µ–ª—ñ MobileNetV2 ===\n",
        "base_model = MobileNetV2(input_shape=IMG_SIZE + (3,), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False  # —Å–ø–æ—á–∞—Ç–∫—É –∑–∞–º–æ—Ä–æ–∂—É—î–º–æ\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1, activation='sigmoid')  # –¥–ª—è binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# === –ù–∞–≤—á–∞–Ω–Ω—è ===\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_data,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "Wdz10AO5oBGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.models import load_model\n",
        "import math\n",
        "\n",
        "# === –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ, –Ω–∞–≤—á–µ–Ω–æ—ó –∑ EarlyStopping ===\n",
        "model = load_model(\"model.h5\")  # –∞–±–æ –º–æ–¥–µ–ª—å, –∑—É–ø–∏–Ω–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ\n",
        "\n",
        "# === –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–ª—è —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö (–ø–æ–≤—Ç–æ—Ä–Ω–æ, —è–∫—â–æ —â–µ –Ω–µ –æ–≥–æ–ª–æ—à–µ–Ω–∏–π) ===\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "test_gen = ImageDataGenerator(rescale=1./255)\n",
        "test_path = 'fracture_dataset/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test'\n",
        "\n",
        "test_data = test_gen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # –¥—É–∂–µ –≤–∞–∂–ª–∏–≤–æ –¥–ª—è –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç—ñ –ø–æ—Ä—è–¥–∫—É\n",
        ")\n",
        "\n",
        "# === –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è ===\n",
        "y_true = test_data.classes  # —Å–ø—Ä–∞–≤–∂–Ω—ñ –∫–ª–∞—Å–∏\n",
        "y_probs = model.predict(test_data, steps=math.ceil(test_data.samples / BATCH_SIZE))\n",
        "y_pred = (y_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "# === –ü–æ–±—É–¥–æ–≤–∞ –º–∞—Ç—Ä–∏—Ü—ñ –ø–æ–º–∏–ª–æ–∫ ===\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"–ü–µ—Ä–µ–ª–æ–º\", \"–ë–µ–∑ –ø–µ—Ä–µ–ª–æ–º—É\"])\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "plt.title(\"–ú–∞—Ç—Ä–∏—Ü—è –ø–æ–º–∏–ª–æ–∫ –º–æ–¥–µ–ª—ñ, –Ω–∞–≤—á–µ–Ω–æ—ó –∑ EarlyStopping\")\n",
        "plt.xlabel(\"–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–æ\")\n",
        "plt.ylabel(\"–§–∞–∫—Ç–∏—á–Ω–æ\")\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gztQ2q99oQnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "\n",
        "# === –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ, —è–∫–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞ –Ω–∞–≤—á–∞–Ω–Ω—è –Ω–∞ 10-–π –µ–ø–æ—Å—ñ ===\n",
        "model = load_model(\"model_es_10epochs.h5\")\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "def predict_fracture(img: Image.Image):\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize(IMG_SIZE)\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    prediction = model.predict(img_array)[0][0]\n",
        "\n",
        "    if prediction < 0.5:\n",
        "        label = \"‚ö†Ô∏è –ú–æ–∂–ª–∏–≤–∏–π –ø–µ—Ä–µ–ª–æ–º\"\n",
        "        confidence = 1 - prediction\n",
        "        color = \"#e74c3c\"\n",
        "        emoji = \"ü¶¥\"\n",
        "    else:\n",
        "        label = \"‚úÖ –ü–µ—Ä–µ–ª–æ–º, –π–º–æ–≤—ñ—Ä–Ω–æ, –≤—ñ–¥—Å—É—Ç–Ω—ñ–π\"\n",
        "        confidence = prediction\n",
        "        color = \"#27ae60\"\n",
        "        emoji = \"üòä\"\n",
        "\n",
        "    confidence_text = f\"–í–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å: {confidence:.2%}\"\n",
        "\n",
        "    html_result = f\"\"\"\n",
        "    <div style=\"\n",
        "        font-family: 'Arial', sans-serif;\n",
        "        border-radius: 12px;\n",
        "        padding: 20px;\n",
        "        background-color: #f7f9fc;\n",
        "        box-shadow: 0 4px 8px rgba(0,0,0,0.1);\n",
        "        max-width: 400px;\n",
        "        margin: auto;\n",
        "        text-align: center;\n",
        "        \">\n",
        "        <h2 style=\"color: {color}; margin-bottom: 5px;\">{emoji} {label}</h2>\n",
        "        <p style=\"font-size: 18px; color: #555;\">{confidence_text}</p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    return img, html_result\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=predict_fracture,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –∑–Ω—ñ–º–æ–∫\"),\n",
        "    outputs=[gr.Image(type=\"pil\", label=\"–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è\"), gr.HTML(label=\"–†–µ–∑—É–ª—å—Ç–∞—Ç\")],\n",
        "    title=\"ü¶¥ –î–µ—Ç–µ–∫—Ç–æ—Ä –ø–µ—Ä–µ–ª–æ–º—ñ–≤\",\n",
        "    description=\"–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ä–µ–Ω—Ç–≥–µ–Ω-–∑–Ω—ñ–º–æ–∫ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ–≥–æ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –ø–µ—Ä–µ–ª–æ–º—É –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –º–æ–¥–µ–ª—ñ.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "id": "ltyPjvLjoTA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === –ü–æ–±—É–¥–æ–≤–∞ –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ —Ç–∞ –≤—Ç—Ä–∞—Ç ===\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# --- Accuracy (–¢–æ—á–Ω—ñ—Å—Ç—å) ---\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title('üìà –¢–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ –ø–æ –µ–ø–æ—Ö–∞—Ö (–∑ EarlyStopping)')\n",
        "plt.xlabel('–ï–ø–æ—Ö–∞')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "\n",
        "# --- Loss (–í—Ç—Ä–∞—Ç–∏) ---\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('üìâ –§—É–Ω–∫—Ü—ñ—è –≤—Ç—Ä–∞—Ç –ø–æ –µ–ø–æ—Ö–∞—Ö (–∑ EarlyStopping)')\n",
        "plt.xlabel('–ï–ø–æ—Ö–∞')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YhFcwM8yoV0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def count_images_by_class(base_path):\n",
        "    class_counts = {}\n",
        "    if not os.path.exists(base_path):\n",
        "        print(f\"‚ö†Ô∏è –®–ª—è—Ö –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {base_path}\")\n",
        "        return class_counts\n",
        "\n",
        "    for class_name in os.listdir(base_path):\n",
        "        class_dir = os.path.join(base_path, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            image_files = [\n",
        "                f for f in os.listdir(class_dir)\n",
        "                if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "            ]\n",
        "            class_counts[class_name] = len(image_files)\n",
        "    return class_counts\n",
        "\n",
        "# –®–ª—è—Ö–∏ –¥–æ —á–∞—Å—Ç–∏–Ω –¥–∞—Ç–∞—Å–µ—Ç—É\n",
        "train_path = '/content/fracture_dataset/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train'\n",
        "val_path   = '/content/fracture_dataset/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/val'\n",
        "test_path  = '/content/fracture_dataset/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test'\n",
        "\n",
        "# –ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫\n",
        "train_counts = count_images_by_class(train_path)\n",
        "val_counts   = count_images_by_class(val_path)\n",
        "test_counts  = count_images_by_class(test_path)\n",
        "\n",
        "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "def plot_distribution(ax, data, title):\n",
        "    if not data:\n",
        "        ax.set_title(f\"{title} (–Ω–µ–º–∞—î –¥–∞–Ω–∏—Ö)\")\n",
        "        ax.axis('off')\n",
        "        return\n",
        "    ax.bar(data.keys(), data.values(), color=['#3498db', '#e67e22'])\n",
        "    ax.set_title(title)\n",
        "    ax.set_ylabel(\"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω—å\")\n",
        "    ax.set_xlabel(\"–ö–ª–∞—Å\")\n",
        "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "plot_distribution(axs[0], train_counts, \"Train\")\n",
        "plot_distribution(axs[1], val_counts, \"Validation\")\n",
        "plot_distribution(axs[2], test_counts, \"Test\")\n",
        "\n",
        "plt.suptitle(\"–†–æ–∑–ø–æ–¥—ñ–ª –∑–æ–±—Ä–∞–∂–µ–Ω—å –ø–æ –∫–ª–∞—Å–∞—Ö —É —Ä—ñ–∑–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω–∞—Ö –¥–∞—Ç–∞—Å–µ—Ç—É\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8eS8UHiQoZc6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}